# 3.1 KNN算法原理与简单实现

> K最近邻(k-Nearest Neighbor，KNN)分类算法，是最简单的机器学习算法之一，涉及高等数学知识近乎为0，虽然它简单，但效果很好，是入门机器学习的首选算法。但很多教程只是一笔带过，在这里通过该算法，我们可以学习到在机器学习中所涉及的其他知识点和需要注意的地方。

- 在之前的鸢尾花数据集中，我们只将2种花的150个样本的前2个特征在二维特征空间中表示，如下图

<img src="https://i.loli.net/2018/11/08/5be4502d4c9d3.png" width="68%"/>

- 那么当来了一个新的数据(如下图中绿色的点)，我们如何判断它最可能属于哪种花呢

<img src="https://i.loli.net/2018/11/08/5be450312459c.png" width="70%"/>

### KNN算法原理

- 我们先取一个k值(即KNN中的"K")，在这里我们先根据经验假设取得了最优值k=3。K近邻算法做的事情就是**对于每个新的点，我们计算出距离它最近的前k个点，然后这k个点进行投票**，在这里k=3，如下图所示

<img src="https://i.loli.net/2018/11/08/5be4503118edd.png" width="70%"/>

- 这个例子中，蓝色:红色为2:1

<img src="https://i.loli.net/2018/11/08/5be45031188bd.png" width="70%"/>

- 因此该新的绿色数据点更有可能属于蓝色类别的花

<img src="https://i.loli.net/2018/11/08/5be450316795b.png" width="70%"/>

- 即KNN算法就是通过**各样本之间的相似程度**(样本空间中的距离)作出判断，因此只考虑1个样本是不具有说服力的，通常我们考虑k为多个

- 这里K近邻解决的就是前面讲到的分类问题，它也可以解决回归问题

### KNN算法的简单实现

- 经过上面的分析我们可以得出该算法大致思路，即判断新来的数据点与其他所有数据的**距离**，距离最近的点的类别即可能为该新点的类别
- 这里模拟了十组数据，每组数据横坐标代表已患肿瘤天数，纵坐标代表对应肿瘤大小，依次对应标记数据：0代表良性肿瘤用绿点表示，1代表恶性肿瘤红点表示

![WX20190328-142302@2x.png](https://i.loli.net/2019/03/28/5c9c7eb6c5ebf.png)

- 这里所用到的数学公式是大家初高中就学习的求两点(x1, y1)与(x2, y2)间距离公式，<img src=https://i.loli.net/2019/03/28/5c9c5e535b80d.png height="25">，即**欧氏距离**公式

<img src=https://i.loli.net/2019/03/28/5c9c7eb657357.png width="600"/>

- 假设现在来了一个新的病人数据(2.5, 2.2)对应图中蓝色点，绘制散点图后我们可以很容易发现其属于红色即恶性肿瘤一类，那么接下来让我们用代码实现吧

<img src=https://i.loli.net/2019/03/28/5c9c7eb6165df.png width="600"/>

<img src=https://i.loli.net/2019/03/28/5c9c82d4f1ae4.png width="600"/>

<img src=https://i.loli.net/2019/03/28/5c9c82d4efe0a.png width="600"/>

<img src=https://i.loli.net/2019/03/28/5c9c82d4f1430.png width="600"/>

- 通过预测结果得出：很遗憾，该病人很可能已经是癌症晚期
---

- 作者：Exrick
- Github地址：https://github.com/Exrick/Machine-Learning
- 版权声明：著作权归作者所有，商业转载请联系作者获得授权，非商业转载请注明出处。
